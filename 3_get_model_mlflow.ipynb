{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'df_train_20201204_1216.parquet',\n",
      "'df_train_20201204_1219.parquet',\n",
      "'df_train_20201212_1545.parquet',\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils_general import beeps\n",
    "from src.utils_general import get_df_parquet\n",
    "from src.utils_model import get_ls_col\n",
    "from src.utils_model import plot_pr_curve\n",
    "dir_train = json.load(open('dir.txt'))['dir_train']\n",
    "dir_models = json.load(open('dir.txt'))['dir_models']\n",
    "dir_mlflow = json.load(open('dir.txt'))['dir_mlflow']\n",
    "mlflow.set_tracking_uri(dir_mlflow)\n",
    "\n",
    "class SklearnModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        return self.model.predict_proba(model_input)[:,1]\n",
    "\n",
    "class RandomForestClassifierFlow():\n",
    "    def __init__(self, params={}, tags={}):\n",
    "        self.model = RandomForestClassifier(**params)\n",
    "        self.params = params\n",
    "        tags['model'] = 'RandomForestClassifier'\n",
    "        self.tags = tags\n",
    "\n",
    "    def mlflow_run(self, df):\n",
    "        with mlflow.start_run() as run:\n",
    "            run_id = run.info.run_uuid\n",
    "            experiment_id = run.info.experiment_id\n",
    "            # train test split\n",
    "            train, test = train_test_split(df, test_size=0.2, random_state=42, stratify=df[['is_profit']])\n",
    "            y = train['is_profit'].copy()\n",
    "            X = train.drop(columns=['is_profit']).copy()\n",
    "            y_test = test['is_profit'].copy()\n",
    "            X_test = test.drop(columns=['is_profit']).copy()\n",
    "            # pipeline\n",
    "            float_cols = df.select_dtypes(include='float64').columns\n",
    "            preprocessor = ColumnTransformer([\n",
    "                ('StandardScaler', StandardScaler(), float_cols),\n",
    "                #('OneHotEncoder', OneHotEncoder(), cat_cols),\n",
    "                ]\n",
    "                ,remainder='passthrough')\n",
    "            full_pipe = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('model', self.model),])\n",
    "            # fit\n",
    "            t_start = time.time()\n",
    "            full_pipe.fit(X, y)\n",
    "            t_training = time.time() - t_start\n",
    "            # predict\n",
    "            t_start = time.time()\n",
    "            y_test_pred_proba = full_pipe.predict_proba(X_test)\n",
    "            t_prediction = time.time() - t_start\n",
    "            # score\n",
    "            proba_threshold = 0.75\n",
    "            metrics = {\n",
    "                'auroc':roc_auc_score(y_test, y_test_pred_proba[:,1]),\n",
    "                'precision':precision_score(y_test, (y_test_pred_proba[:,1]>proba_threshold)),\n",
    "                't_training':t_training,\n",
    "                't_prediction':t_prediction,\n",
    "            }\n",
    "            # log params, metrics, tags\n",
    "            mlflow.log_params(self.params)\n",
    "            mlflow.log_metrics(metrics)\n",
    "            mlflow.set_tags(self.tags)\n",
    "            # log Model\n",
    "            #mlflow.sklearn.log_model(full_pipe, artifact_path='model')\n",
    "            #wrapped_model = SklearnModelWrapper(full_pipe)\n",
    "            #mlflow.pyfunc.log_model('model', python_model=wrapped_model)\n",
    "            return full_pipe\n",
    "\n",
    "[print(f\"'{x}',\") for x in os.listdir(dir_train) if x[-8:]=='.parquet'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-29 2020-12-11\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 206857 entries, 83 to 171\n",
      "Data columns (total 21 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   is_profit                 206857 non-null  bool   \n",
      " 1   rsi14                     206857 non-null  float64\n",
      " 2   sma9_var                  206857 non-null  float64\n",
      " 3   sma180_var                206857 non-null  float64\n",
      " 4   vwap_var                  206857 non-null  float64\n",
      " 5   spread14_e                206857 non-null  float64\n",
      " 6   volume14_34_var           206857 non-null  float64\n",
      " 7   prev_close_var            206857 non-null  float64\n",
      " 8   prev_floor_var            206857 non-null  float64\n",
      " 9   prev_ceil_var             206857 non-null  float64\n",
      " 10  prev1_candle_score        206857 non-null  float64\n",
      " 11  prev2_candle_score        206857 non-null  float64\n",
      " 12  prev3_candle_score        206857 non-null  float64\n",
      " 13  mins_from_start           206857 non-null  float64\n",
      " 14  valley_interval_mins      206857 non-null  float64\n",
      " 15  valley_close_score        206857 non-null  float64\n",
      " 16  valley_rsi_score          206857 non-null  float64\n",
      " 17  day_open_var              206857 non-null  float64\n",
      " 18  open_from_prev_close_var  206857 non-null  float64\n",
      " 19  ceil_var                  206857 non-null  float64\n",
      " 20  floor_var                 206857 non-null  float64\n",
      "dtypes: bool(1), float64(20)\n",
      "memory usage: 33.3 MB\n"
     ]
    }
   ],
   "source": [
    "# df_train - Import\n",
    "ls_f = [   \n",
    "    'df_train_20201204_1216.parquet',\n",
    "    'df_train_20201204_1219.parquet',\n",
    "    'df_train_20201212_1545.parquet',\n",
    "]\n",
    "df = get_df_parquet(ls_f, dir_train)\n",
    "\n",
    "# df_train - Remove outliers and non-relevant data \n",
    "q = '''\n",
    "    divergence=='bull_reg'\\\n",
    "    and prev_close>5\\\n",
    "    and abs(sma9_var)<0.02\\\n",
    "    and abs(sma180_var)<0.2\\\n",
    "    and abs(vwap_var)<0.2\\\n",
    "    and abs(spread14_e)<0.02\\\n",
    "    and abs(prev_close_var)<0.5\\\n",
    "    and abs(prev_floor_var)<0.5\\\n",
    "    and abs(prev_ceil_var)<0.5\\\n",
    "    and abs(prev1_candle_score)<0.02\\\n",
    "    and abs(prev2_candle_score)<0.02\\\n",
    "    and abs(prev3_candle_score)<0.02\\\n",
    "    and mins_from_start<300\\\n",
    "    and valley_interval_mins<200\\\n",
    "    and valley_close_score<10\\\n",
    "    and abs(day_open_var)<1.5\\\n",
    "    and abs(open_from_prev_close_var)<0.4\\\n",
    "    and abs(ceil_var)<0.2\\\n",
    "    and abs(floor_var)<0.2\\\n",
    "'''\n",
    "df = df.query(q)\n",
    "\n",
    "# df_train - get dates\n",
    "df = df[df['datetime'].dt.date.astype('str')>'2020-06-28']\n",
    "inputs_date_start = df['datetime'].dt.date.astype('str').unique().min()\n",
    "inputs_date_end = df['datetime'].dt.date.astype('str').unique().max()\n",
    "print(inputs_date_start, inputs_date_end)\n",
    "\n",
    "# df_train - Remove unwanted columns\n",
    "ls_col_remove = [\n",
    "    'sym',\n",
    "    'datetime',\n",
    "    'prev_close',\n",
    "    'divergence',\n",
    "    'profit',\n",
    "    ###\n",
    "    #'valley_interval_mins',\n",
    "    #'floor_var',\n",
    "    #'sma9_var',\n",
    "    #'prev_close_var',\n",
    "    #'ceil_var',\n",
    "    #'prev_ceil_var',\n",
    "]\n",
    "df = df.drop(columns=ls_col_remove)\n",
    "ls_col = list(df.drop(columns='is_profit'))\n",
    "\n",
    "# df-train - Preview\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 2048,\n",
    "    'max_features': 3,\n",
    "    'min_samples_leaf': 2,\n",
    "    'min_samples_split': 2,\n",
    "    'n_estimators': 800,\n",
    "    ###\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42,\n",
    "}\n",
    "params = {\n",
    "    'criterion': 'entropy',\n",
    "    'max_depth': 1000,\n",
    "    'max_features': 'sqrt',\n",
    "    'min_samples_leaf': 4,\n",
    "    'min_samples_split': 5,\n",
    "    'n_estimators': 600,\n",
    "    ###\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42,\n",
    "}\n",
    "tags = {\n",
    "    'inputs_date_start':inputs_date_start,\n",
    "    'inputs_date_end':inputs_date_end,\n",
    "    'df_train files':str(ls_f),\n",
    "    'comments':''\n",
    "}\n",
    "rfcf = RandomForestClassifierFlow(params, tags)\n",
    "full_pipe = rfcf.mlflow_run(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Michael/five_minute_midas/data/models/tup_model_2020-12-06_1640.p'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "tup_model = (q, ls_col, full_pipe)\n",
    "f = f'{dir_models}tup_model_{timestamp}.p'\n",
    "pickle.dump(tup_model, open(f, 'wb'))\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': ['entropy', 'gini'],\n",
      " 'max_depth': [1000, 2000, 3000, 4000],\n",
      " 'max_features': ['auto', 'sqrt', 'log2', None],\n",
      " 'min_samples_leaf': [4, 6, 8, 12],\n",
      " 'min_samples_split': [5, 7, 10, 14],\n",
      " 'n_estimators': [400, 600, 800]}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "random_grid = {\n",
    "    'n_estimators': [800], # Number of trees in random forest\n",
    "    'max_depth': [2048, None],\n",
    "    'max_features': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "}\n",
    "\n",
    "random_grid = {\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_depth': [1000, 2000, 3000, 4000],\n",
    "    'max_features': ['auto', 'sqrt','log2', None],\n",
    "    'min_samples_leaf': [4, 6, 8, 12],\n",
    "    'min_samples_split': [5, 7, 10, 14],\n",
    "    'n_estimators': [400, 600, 800]\n",
    "}\n",
    "pprint.pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 155.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=RandomForestClassifier(), n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
       "                                        'max_depth': [1000, 2000, 3000, 4000],\n",
       "                                        'max_features': ['auto', 'sqrt', 'log2',\n",
       "                                                         None],\n",
       "                                        'min_samples_leaf': [4, 6, 8, 12],\n",
       "                                        'min_samples_split': [5, 7, 10, 14],\n",
       "                                        'n_estimators': [400, 600, 800]},\n",
       "                   random_state=42, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "model = RandomForestClassifier()\n",
    "model_random_cv = RandomizedSearchCV(\n",
    "    estimator = model,\n",
    "    param_distributions = random_grid,\n",
    "    n_iter = 20,\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs = -1,\n",
    "    scoring = 'roc_auc'\n",
    ")\n",
    "# Run random search\n",
    "y = df['is_profit'].copy()\n",
    "X = df.drop(columns=['is_profit']).copy()\n",
    "model_random_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy',\n",
      " 'max_depth': 1000,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 5,\n",
      " 'n_estimators': 600}\n",
      "0.74798\n",
      "\n",
      "{'criterion': 'entropy',\n",
      " 'max_depth': 2000,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 5,\n",
      " 'n_estimators': 400}\n",
      "0.74766\n",
      "\n",
      "{'criterion': 'entropy',\n",
      " 'max_depth': 1000,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 7,\n",
      " 'n_estimators': 600}\n",
      "0.74765\n",
      "\n",
      "{'criterion': 'entropy',\n",
      " 'max_depth': 4000,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 10,\n",
      " 'n_estimators': 400}\n",
      "0.74763\n",
      "\n",
      "{'criterion': 'entropy',\n",
      " 'max_depth': 2000,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 7,\n",
      " 'n_estimators': 600}\n",
      "0.7475\n",
      "\n",
      "{'criterion': 'entropy',\n",
      " 'max_depth': 1000,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 10,\n",
      " 'n_estimators': 400}\n",
      "0.74729\n",
      "\n",
      "{'criterion': 'gini',\n",
      " 'max_depth': 2000,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 10,\n",
      " 'n_estimators': 800}\n",
      "0.74703\n",
      "\n",
      "{'criterion': 'gini',\n",
      " 'max_depth': 3000,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 7,\n",
      " 'n_estimators': 800}\n",
      "0.747\n",
      "\n",
      "{'criterion': 'gini',\n",
      " 'max_depth': 2000,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 10,\n",
      " 'n_estimators': 600}\n",
      "0.74689\n",
      "\n",
      "{'criterion': 'gini',\n",
      " 'max_depth': 2000,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 12,\n",
      " 'min_samples_split': 7,\n",
      " 'n_estimators': 800}\n",
      "0.74684\n",
      "\n",
      "{'criterion': 'gini',\n",
      " 'max_depth': 4000,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 5,\n",
      " 'n_estimators': 600}\n",
      "0.74682\n",
      "\n",
      "{'criterion': 'gini',\n",
      " 'max_depth': 3000,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 10,\n",
      " 'n_estimators': 600}\n",
      "0.74678\n",
      "\n",
      "{'criterion': 'gini',\n",
      " 'max_depth': 4000,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 12,\n",
      " 'min_samples_split': 14,\n",
      " 'n_estimators': 800}\n",
      "0.74677\n",
      "\n",
      "{'criterion': 'gini',\n",
      " 'max_depth': 2000,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 7,\n",
      " 'n_estimators': 600}\n",
      "0.7467\n",
      "\n",
      "{'criterion': 'gini',\n",
      " 'max_depth': 3000,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 12,\n",
      " 'min_samples_split': 14,\n",
      " 'n_estimators': 400}\n",
      "0.74645\n",
      "\n",
      "{'criterion': 'entropy',\n",
      " 'max_depth': 4000,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 12,\n",
      " 'min_samples_split': 5,\n",
      " 'n_estimators': 600}\n",
      "0.74507\n",
      "\n",
      "{'criterion': 'entropy',\n",
      " 'max_depth': 2000,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 14,\n",
      " 'n_estimators': 800}\n",
      "0.74493\n",
      "\n",
      "{'criterion': 'gini',\n",
      " 'max_depth': 4000,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 12,\n",
      " 'min_samples_split': 10,\n",
      " 'n_estimators': 600}\n",
      "0.74427\n",
      "\n",
      "{'criterion': 'gini',\n",
      " 'max_depth': 4000,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 7,\n",
      " 'n_estimators': 800}\n",
      "0.74344\n",
      "\n",
      "{'criterion': 'gini',\n",
      " 'max_depth': 1000,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 5,\n",
      " 'n_estimators': 400}\n",
      "0.74302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for tup in sorted(zip(model_random_cv.cv_results_['params'], model_random_cv.cv_results_['mean_test_score']), key = lambda x: x[1], reverse=1):\n",
    "    pprint.pprint(tup[0])\n",
    "    print(round(tup[1], 5))\n",
    "    print()\n",
    "beeps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
